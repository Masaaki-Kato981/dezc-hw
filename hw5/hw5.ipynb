{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d4037d-10ae-4a37-bd94-b6d0e162190d",
   "metadata": {},
   "source": [
    "## Question 1: Install Spark and PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ea1faff-1774-418d-ba5e-dee431ecec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PySpark 3.5.4 version is running...\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "import os\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f'The PySpark {spark.version} version is running...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f3db1-7506-47fc-8974-af6a63054650",
   "metadata": {},
   "source": [
    "## Question 2: Yellow October 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b93f9cc-cd3e-453f-bdb7-73f1199a6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# assume data saved locally in current working directory\n",
    "df = spark.read.parquet('yellow_tripdata_2024-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab520cb7-fe98-43df-b785-2b907ccdc3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Repartition the Dataframe to 4 partitions and save it to parquet\n",
    "main_dir = 'yellow_2024_04'\n",
    "df = df.repartition(4)\n",
    "df.write.mode(\"overwrite\").parquet(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a47648d-b0d8-4fbe-8718-c86443da9b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.409375190734863\n",
      "22.38893699645996\n",
      "22.388922691345215\n",
      "22.404443740844727\n"
     ]
    }
   ],
   "source": [
    "# get file size of partition data\n",
    "parquet_files = [f for f in os.listdir(main_dir) if f.endswith('.parquet')]\n",
    "for i in parquet_files:\n",
    "    size_mb = os.path.getsize(f'{main_dir}/{i}') / (1024 * 1024)\n",
    "    print(size_mb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c63b7-346f-45d8-994e-4ee6a12d3ae1",
   "metadata": {},
   "source": [
    "## Question 3: Count records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c124e9ea-0e04-4b56-bf1c-4cb32eee43fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  128893|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# taxi trips that start in 10/15/2024\n",
    "df.createOrReplaceTempView(\"trips\")\n",
    "spark.sql(\"\"\"SELECT COUNT(*)\n",
    "             from trips\n",
    "             WHERE DATE(tpep_pickup_datetime)  = '2024-10-15'\n",
    "         \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5612940-e219-48aa-ac23-37a6582dceea",
   "metadata": {},
   "source": [
    "## Question 4: Longest Trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b7cc57f-bd66-4756-b077-a6407cc9a9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|VendorID|         trip_hour|\n",
      "+--------+------------------+\n",
      "|       2|162.61777777777777|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_unix = df \\\n",
    "            .withColumn('pickup_unix', F.unix_timestamp(df.tpep_pickup_datetime) ) \\\n",
    "            .withColumn('dropoff_unix', F.unix_timestamp(df.tpep_dropoff_datetime) )\n",
    "df_trip_dur = df_unix \\\n",
    "                    .withColumn('trip_hour', (df_unix.dropoff_unix - df_unix.pickup_unix) / 3600)\n",
    "df_trip_dur.createOrReplaceTempView(\"trips_dur\")\n",
    "spark.sql(\"\"\"\n",
    "          SELECT VendorID, trip_hour\n",
    "          FROM trips_dur\n",
    "          ORDER BY trip_hour DESC\n",
    "          LIMIT 1\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe1b9f-998b-4aca-aeda-95a7004f4d7e",
   "metadata": {},
   "source": [
    "## Question 6: Least frequent pickup location zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c6d0c78-ef3a-46fd-9c58-7280981b2e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lookup data (assumes saved in working directory)\n",
    "df_lookup = spark.read.option(\"header\", \"true\").csv('taxi_zone_lookup.csv')\n",
    "df_lookup_clean = df_lookup \\\n",
    "                        .withColumn(\"lo_id\", F.col(\"LocationID\").cast(IntegerType()) )\n",
    "df_lookup_clean.createOrReplaceTempView(\"lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb15123b-958e-4134-96d2-829b0849b7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('LocationID', StringType(), True), StructField('Borough', StringType(), True), StructField('Zone', StringType(), True), StructField('service_zone', StringType(), True), StructField('lo_id', IntegerType(), True)])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lookup_clean.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "387e5e96-0e6a-417f-abf2-fb3feb372858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampNTZType(), True), StructField('tpep_dropoff_datetime', TimestampNTZType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('Airport_fee', DoubleType(), True)])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5fa14b98-c043-4f75-bcee-ab6b29e62bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+--------+\n",
      "|zone                                         |count(1)|\n",
      "+---------------------------------------------+--------+\n",
      "|Governor's Island/Ellis Island/Liberty Island|1       |\n",
      "+---------------------------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "         SELECT l.zone, COUNT(*)\n",
    "         FROM trips as t\n",
    "         LEFT JOIN lookup as l\n",
    "         ON t.PULocationID = l.lo_id\n",
    "         GROUP BY l.zone\n",
    "         ORDER BY COUNT(*)\n",
    "         LIMIT 1\n",
    "         \"\"\").show(truncate = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
